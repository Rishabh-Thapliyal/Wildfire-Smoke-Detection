{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "023c76bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-02 10:18:05 [config.py:213] Replacing legacy 'type' key with 'rope_type'\n",
      "WARNING 06-02 10:18:05 [config.py:220] Replacing legacy rope_type 'su' with 'longrope'\n",
      "WARNING 06-02 10:18:05 [config.py:3096] Your Tesla V100-SXM2-32GB device (with compute capability 7.0) doesn't support torch.bfloat16. Falling back to torch.float16 for compatibility.\n",
      "WARNING 06-02 10:18:05 [config.py:3135] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 06-02 10:18:05 [config.py:793] This model supports multiple tasks: {'embed', 'generate', 'score', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 06-02 10:18:05 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.0.1) with config: model='microsoft/Phi-3.5-vision-instruct', speculative_config=None, tokenizer='microsoft/Phi-3.5-vision-instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=microsoft/Phi-3.5-vision-instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, pooler_config=None, compilation_config={\"compile_sizes\": [], \"inductor_compile_config\": {\"enable_auto_functionalized_v2\": false}, \"cudagraph_capture_sizes\": [256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176, 168, 160, 152, 144, 136, 128, 120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 4, 2, 1], \"max_capture_size\": 256}, use_cached_outputs=False, \n",
      "INFO 06-02 10:18:05 [cuda.py:240] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 06-02 10:18:05 [cuda.py:289] Using XFormers backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "/usr/local/lib/python3.10/dist-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLM\n\u001b[0;32m----> 3\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/Phi-3.5-vision-instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Required to load Phi-3.5-vision\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_model_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Otherwise, it may not fit in smaller GPUs\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit_mm_per_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# The maximum number to accept\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Refer to the HuggingFace repo for the correct format to use\u001b[39;00m\n\u001b[1;32m     11\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|user|>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m<|image_1|>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mWhat is the content of each image?<|end|>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m<|assistant|>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/utils.py:1183\u001b[0m, in \u001b[0;36mdeprecate_args.<locals>.wrapper.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1178\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1179\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[1;32m   1180\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         )\n\u001b[0;32m-> 1183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/entrypoints/llm.py:253\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_token, hf_overrides, mm_processor_kwargs, task, override_pooler_config, compilation_config, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m EngineArgs(\n\u001b[1;32m    224\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    225\u001b[0m     task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    250\u001b[0m )\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Create the Engine (autoselects V0 vs V1)\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUsageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/engine/llm_engine.py:501\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMEngine \u001b[38;5;28;01mas\u001b[39;00m V1LLMEngine\n\u001b[1;32m    499\u001b[0m     engine_cls \u001b[38;5;241m=\u001b[39m V1LLMEngine\n\u001b[0;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_vllm_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/engine/llm_engine.py:477\u001b[0m, in \u001b[0;36mLLMEngine.from_vllm_config\u001b[0;34m(cls, vllm_config, usage_context, stat_loggers, disable_log_stats)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_vllm_config\u001b[39m(\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    475\u001b[0m     disable_log_stats: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    476\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLMEngine\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_executor_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/engine/llm_engine.py:265\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, vllm_config, executor_class, log_stats, usage_context, stat_loggers, mm_registry, use_cached_outputs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config_fields \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mtry_get_generation_config())\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_preprocessor \u001b[38;5;241m=\u001b[39m InputPreprocessor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config,\n\u001b[1;32m    262\u001b[0m                                             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer,\n\u001b[1;32m    263\u001b[0m                                             mm_registry)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_executor \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mrunner_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpooling\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_kv_caches()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/executor/executor_base.py:52\u001b[0m, in \u001b[0;36mExecutorBase.__init__\u001b[0;34m(self, vllm_config)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_adapter_config \u001b[38;5;241m=\u001b[39m vllm_config\u001b[38;5;241m.\u001b[39mprompt_adapter_config\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;241m=\u001b[39m vllm_config\u001b[38;5;241m.\u001b[39mobservability_config\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_sleeping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msleeping_tags: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py:45\u001b[0m, in \u001b[0;36mUniProcExecutor._init_executor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m is_driver_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     38\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     39\u001b[0m     vllm_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvllm_config,\n\u001b[1;32m     40\u001b[0m     local_rank\u001b[38;5;241m=\u001b[39mlocal_rank,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     is_driver_worker\u001b[38;5;241m=\u001b[39mis_driver_worker,\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollective_rpc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_worker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollective_rpc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_device\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollective_rpc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py:56\u001b[0m, in \u001b[0;36mUniProcExecutor.collective_rpc\u001b[0;34m(self, method, timeout, args, kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 56\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mrun_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [answer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/utils.py:2605\u001b[0m, in \u001b[0;36mrun_method\u001b[0;34m(obj, method, args, kwargs)\u001b[0m\n\u001b[1;32m   2603\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2604\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(method, obj)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 2605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/worker/worker_base.py:594\u001b[0m, in \u001b[0;36mWorkerWrapperBase.init_worker\u001b[0;34m(self, all_kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInjected \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m into \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m for extended collective_rpc calls \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    591\u001b[0m             worker_extension_cls, worker_class, extended_calls)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_current_vllm_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvllm_config):\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;66;03m# To make vLLM config available during worker initialization\u001b[39;00m\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker \u001b[38;5;241m=\u001b[39m \u001b[43mworker_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/worker/worker.py:86\u001b[0m, in \u001b[0;36mWorker.__init__\u001b[0;34m(self, vllm_config, local_rank, rank, distributed_init_method, is_driver_worker, model_runner_cls)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n\u001b[1;32m     85\u001b[0m     ModelRunnerClass \u001b[38;5;241m=\u001b[39m EncoderDecoderModelRunner\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_runner: GPUModelRunnerBase \u001b[38;5;241m=\u001b[39m \u001b[43mModelRunnerClass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_cache_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_driver_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_driver_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mspeculative_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_runner_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_runner \u001b[38;5;241m=\u001b[39m model_runner_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_runner)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/worker/model_runner.py:1124\u001b[0m, in \u001b[0;36mGPUModelRunnerBase.__init__\u001b[0;34m(self, vllm_config, kv_cache_dtype, is_driver_worker, return_hidden_states, input_registry, mm_registry)\u001b[0m\n\u001b[1;32m   1119\u001b[0m num_attn_heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mget_num_attention_heads(\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_config)\n\u001b[1;32m   1121\u001b[0m needs_attn_backend \u001b[38;5;241m=\u001b[39m (num_attn_heads \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1122\u001b[0m                       \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mis_attention_free)\n\u001b[0;32m-> 1124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_backend \u001b[38;5;241m=\u001b[39m \u001b[43mget_attn_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_head_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_attention_free\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_mla\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_mla\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m needs_attn_backend \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_backend:\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_backend\u001b[38;5;241m.\u001b[39mget_state_cls()(\n\u001b[1;32m   1134\u001b[0m         weakref\u001b[38;5;241m.\u001b[39mproxy(\u001b[38;5;28mself\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/attention/selector.py:95\u001b[0m, in \u001b[0;36mget_attn_backend\u001b[0;34m(head_size, dtype, kv_cache_dtype, block_size, is_attention_free, is_blocksparse, use_mla)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Selects which attention backend to use and lazily imports it.\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Accessing envs.* behind an @lru_cache decorator can cause the wrong\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# value to be returned from the cache if the value changes between calls.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# To avoid this, we read envs.VLLM_USE_V1 here and pass it explicitly to the\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# private function.\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cached_get_attn_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_cache_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_attention_free\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_attention_free\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_blocksparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_blocksparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_v1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVLLM_USE_V1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_mla\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_mla\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/attention/selector.py:154\u001b[0m, in \u001b[0;36m_cached_get_attn_backend\u001b[0;34m(head_size, dtype, kv_cache_dtype, block_size, is_attention_free, is_blocksparse, use_v1, use_mla)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m attention_cls:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid attention backend for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_platform\u001b[38;5;241m.\u001b[39mdevice_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresolve_obj_by_qualname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_cls\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/utils.py:2191\u001b[0m, in \u001b[0;36mresolve_obj_by_qualname\u001b[0;34m(qualname)\u001b[0m\n\u001b[1;32m   2187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2188\u001b[0m \u001b[38;5;124;03mResolve an object by its fully qualified name.\u001b[39;00m\n\u001b[1;32m   2189\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2190\u001b[0m module_name, obj_name \u001b[38;5;241m=\u001b[39m qualname\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2191\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, obj_name)\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/attention/backends/xformers.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Tuple, Type\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops \u001b[38;5;28;01mas\u001b[39;00m xops\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmha\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattn_bias\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (AttentionBias,\n\u001b[1;32m      9\u001b[0m                                          BlockDiagonalCausalMask,\n\u001b[1;32m     10\u001b[0m                                          BlockDiagonalMask,\n\u001b[1;32m     11\u001b[0m                                          LowerTriangularMaskWithTensorBias)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabstract\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (AttentionBackend, AttentionImpl,\n\u001b[1;32m     14\u001b[0m                                               AttentionLayer,\n\u001b[1;32m     15\u001b[0m                                               AttentionMetadata, AttentionType)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xformers/ops/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the BSD license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmha\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     AttentionBias,\n\u001b[1;32m     11\u001b[0m     AttentionOp,\n\u001b[1;32m     12\u001b[0m     AttentionOpBase,\n\u001b[1;32m     13\u001b[0m     LowerTriangularMask,\n\u001b[1;32m     14\u001b[0m     MemoryEfficientAttentionCkOp,\n\u001b[1;32m     15\u001b[0m     MemoryEfficientAttentionCutlassFwdFlashBwOp,\n\u001b[1;32m     16\u001b[0m     MemoryEfficientAttentionCutlassOp,\n\u001b[1;32m     17\u001b[0m     MemoryEfficientAttentionFlashAttentionOp,\n\u001b[1;32m     18\u001b[0m     MemoryEfficientAttentionSplitKCkOp,\n\u001b[1;32m     19\u001b[0m     memory_efficient_attention,\n\u001b[1;32m     20\u001b[0m     memory_efficient_attention_backward,\n\u001b[1;32m     21\u001b[0m     memory_efficient_attention_forward,\n\u001b[1;32m     22\u001b[0m     memory_efficient_attention_forward_requires_grad,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m index_select_cat, scaled_index_add\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodpar_layers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColumnParallelLinear, RowParallelLinear\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py:10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, List, Optional, Sequence, Tuple, Type, Union, cast\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     attn_bias,\n\u001b[1;32m     12\u001b[0m     ck,\n\u001b[1;32m     13\u001b[0m     ck_decoder,\n\u001b[1;32m     14\u001b[0m     ck_splitk,\n\u001b[1;32m     15\u001b[0m     cutlass,\n\u001b[1;32m     16\u001b[0m     flash,\n\u001b[1;32m     17\u001b[0m     flash3,\n\u001b[1;32m     18\u001b[0m     triton_splitk,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattn_bias\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     VARLEN_BIASES,\n\u001b[1;32m     22\u001b[0m     AttentionBias,\n\u001b[1;32m     23\u001b[0m     BlockDiagonalMask,\n\u001b[1;32m     24\u001b[0m     LowerTriangularMask,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     AttentionBwOpBase,\n\u001b[1;32m     28\u001b[0m     AttentionFwOpBase,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     bmk2bmhk,\n\u001b[1;32m     35\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:63\u001b[0m\n\u001b[1;32m     60\u001b[0m     VARLEN_LSE_PACKED \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mfind_spec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflash_attn\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mflash_attn\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mflash_attn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflash_attn_interface\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(flash_attn\u001b[38;5;241m.\u001b[39mflash_attn_interface, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflash_attn_cuda\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/flash_attn/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.4.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflash_attn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflash_attn_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     flash_attn_func,\n\u001b[1;32m      5\u001b[0m     flash_attn_kvpacked_func,\n\u001b[1;32m      6\u001b[0m     flash_attn_qkvpacked_func,\n\u001b[1;32m      7\u001b[0m     flash_attn_varlen_func,\n\u001b[1;32m      8\u001b[0m     flash_attn_varlen_kvpacked_func,\n\u001b[1;32m      9\u001b[0m     flash_attn_varlen_qkvpacked_func,\n\u001b[1;32m     10\u001b[0m     flash_attn_with_kvcache,\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/flash_attn/flash_attn_interface.py:10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# We need to import the CUDA kernels after importing torch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mflash_attn_2_cuda\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mflash_attn_cuda\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# isort: on\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_block_size\u001b[39m(device, head_dim, is_dropout, is_causal):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# This should match the block sizes in the CUDA kernel\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.10/dist-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi"
     ]
    }
   ],
   "source": [
    "from vllm import LLM\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"microsoft/Phi-3.5-vision-instruct\",\n",
    "    trust_remote_code=True,  # Required to load Phi-3.5-vision\n",
    "    max_model_len=4096,  # Otherwise, it may not fit in smaller GPUs\n",
    "    limit_mm_per_prompt={\"image\": 2},  # The maximum number to accept\n",
    ")\n",
    "\n",
    "# Refer to the HuggingFace repo for the correct format to use\n",
    "prompt = \"<|user|>\\n<|image_1|>\\nWhat is the content of each image?<|end|>\\n<|assistant|>\\n\"\n",
    "\n",
    "# Load the images using PIL.Image\n",
    "image1 = PIL.Image.open(\"http://legacy-www.hpwren.ucsd.edu/FIgLib/HPWREN-FIgLib-Data/20250107_PalisadesFire_69bravo-e-mobo-c/1736274241_%2B00000.jpg\")\n",
    "image2 = PIL.Image.open(\"http://legacy-www.hpwren.ucsd.edu/FIgLib/HPWREN-FIgLib-Data/20250107_PalisadesFire_69bravo-e-mobo-c/1736274241_%2B00000.jpg\")\n",
    "\n",
    "outputs = llm.generate({\n",
    "    \"prompt\": prompt,\n",
    "    \"multi_modal_data\": {\n",
    "        \"image\": [image1]\n",
    "    },\n",
    "    \n",
    "})\n",
    "\n",
    "for o in outputs:\n",
    "    generated_text = o.outputs[0].text\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb2e660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rthapliyal/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-02 10:27:16 [__init__.py:243] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 10:27:19,262\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-02 10:27:19 [__init__.py:31] Available plugins for group vllm.general_plugins:\n",
      "INFO 06-02 10:27:19 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver\n",
      "INFO 06-02 10:27:19 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.\n",
      "ERROR 06-02 10:27:28 [registry.py:363] Error in inspecting model architecture 'LlavaForConditionalGeneration'\n",
      "ERROR 06-02 10:27:28 [registry.py:363] Traceback (most recent call last):\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/vllm/model_executor/models/registry.py\", line 594, in _run_in_subprocess\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     returned.check_returncode()\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/usr/lib/python3.10/subprocess.py\", line 457, in check_returncode\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     raise CalledProcessError(self.returncode, self.args, self.stdout,\n",
      "ERROR 06-02 10:27:28 [registry.py:363] subprocess.CalledProcessError: Command '['/usr/bin/python', '-m', 'vllm.model_executor.models.registry']' returned non-zero exit status 1.\n",
      "ERROR 06-02 10:27:28 [registry.py:363] \n",
      "ERROR 06-02 10:27:28 [registry.py:363] The above exception was the direct cause of the following exception:\n",
      "ERROR 06-02 10:27:28 [registry.py:363] \n",
      "ERROR 06-02 10:27:28 [registry.py:363] Traceback (most recent call last):\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/vllm/model_executor/models/registry.py\", line 361, in _try_inspect_model_cls\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     return model.inspect_model_cls()\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/vllm/model_executor/models/registry.py\", line 332, in inspect_model_cls\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     return _run_in_subprocess(\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/vllm/model_executor/models/registry.py\", line 597, in _run_in_subprocess\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     raise RuntimeError(f\"Error raised in subprocess:\\n\"\n",
      "ERROR 06-02 10:27:28 [registry.py:363] RuntimeError: Error raised in subprocess:\n",
      "ERROR 06-02 10:27:28 [registry.py:363] /usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'vllm.model_executor.models.registry' found in sys.modules after import of package 'vllm.model_executor.models', but prior to execution of 'vllm.model_executor.models.registry'; this may result in unpredictable behaviour\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   warn(RuntimeWarning(msg))\n",
      "ERROR 06-02 10:27:28 [registry.py:363] Traceback (most recent call last):\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 2009, in _get_module\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     return _bootstrap._gcd_import(name[level:], package, level)\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 61, in <module>\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     from .integrations.flash_attention import flash_attention_forward\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/transformers/integrations/flash_attention.py\", line 5, in <module>\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     from ..modeling_flash_attention_utils import _flash_attention_forward, flash_attn_supports_top_left_mask\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py\", line 36, in <module>\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/usr/local/lib/python3.10/dist-packages/flash_attn/__init__.py\", line 3, in <module>\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     from flash_attn.flash_attn_interface import (\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/usr/local/lib/python3.10/dist-packages/flash_attn/flash_attn_interface.py\", line 10, in <module>\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     import flash_attn_2_cuda as flash_attn_cuda\n",
      "ERROR 06-02 10:27:28 [registry.py:363] ImportError: /usr/local/lib/python3.10/dist-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi\n",
      "ERROR 06-02 10:27:28 [registry.py:363] \n",
      "ERROR 06-02 10:27:28 [registry.py:363] The above exception was the direct cause of the following exception:\n",
      "ERROR 06-02 10:27:28 [registry.py:363] \n",
      "ERROR 06-02 10:27:28 [registry.py:363] Traceback (most recent call last):\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     return _run_code(code, main_globals, None,\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     exec(code, run_globals)\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/vllm/model_executor/models/registry.py\", line 618, in <module>\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     _run()\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/vllm/model_executor/models/registry.py\", line 611, in _run\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     result = fn()\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/vllm/model_executor/models/registry.py\", line 333, in <lambda>\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     lambda: _ModelInfo.from_model_cls(self.load_model_cls()))\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/vllm/model_executor/models/registry.py\", line 336, in load_model_cls\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     mod = importlib.import_module(self.module_name)\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     return _bootstrap._gcd_import(name[level:], package, level)\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/vllm/model_executor/models/llava.py\", line 40, in <module>\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     from .pixtral import PixtralHFEncoderInfo, PixtralHFVisionModel\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/vllm/model_executor/models/pixtral.py\", line 21, in <module>\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     from transformers.models.pixtral.modeling_pixtral import (\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/transformers/models/pixtral/modeling_pixtral.py\", line 23, in <module>\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     from ... import PreTrainedModel\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1997, in __getattr__\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     module = self._get_module(self._class_to_module[name])\n",
      "ERROR 06-02 10:27:28 [registry.py:363]   File \"/home/rthapliyal/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 2011, in _get_module\n",
      "ERROR 06-02 10:27:28 [registry.py:363]     raise RuntimeError(\n",
      "ERROR 06-02 10:27:28 [registry.py:363] RuntimeError: Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):\n",
      "ERROR 06-02 10:27:28 [registry.py:363] /usr/local/lib/python3.10/dist-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi\n",
      "ERROR 06-02 10:27:28 [registry.py:363] \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model architectures ['LlavaForConditionalGeneration'] failed to be inspected. Please check the logs for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLM\n\u001b[0;32m----> 3\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllava-hf/llava-1.5-7b-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Refer to the HuggingFace repo for the correct format to use\u001b[39;00m\n\u001b[1;32m      6\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSER: <image>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mWhat is the content of this image?\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mASSISTANT:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/utils.py:1183\u001b[0m, in \u001b[0;36mdeprecate_args.<locals>.wrapper.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1178\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1179\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[1;32m   1180\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         )\n\u001b[0;32m-> 1183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/entrypoints/llm.py:253\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_token, hf_overrides, mm_processor_kwargs, task, override_pooler_config, compilation_config, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m EngineArgs(\n\u001b[1;32m    224\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    225\u001b[0m     task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    250\u001b[0m )\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Create the Engine (autoselects V0 vs V1)\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUsageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/engine/llm_engine.py:494\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates an LLM engine from the engine arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Create the engine configs.\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m vllm_config \u001b[38;5;241m=\u001b[39m \u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_engine_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m engine_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m envs\u001b[38;5;241m.\u001b[39mVLLM_USE_V1:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/engine/arg_utils.py:983\u001b[0m, in \u001b[0;36mEngineArgs.create_engine_config\u001b[0;34m(self, usage_context)\u001b[0m\n\u001b[1;32m    980\u001b[0m current_platform\u001b[38;5;241m.\u001b[39mpre_register_and_update()\n\u001b[1;32m    982\u001b[0m device_config \u001b[38;5;241m=\u001b[39m DeviceConfig(device\u001b[38;5;241m=\u001b[39mcurrent_platform\u001b[38;5;241m.\u001b[39mdevice_type)\n\u001b[0;32m--> 983\u001b[0m model_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# * If VLLM_USE_V1 is unset, we enable V1 for \"supported features\"\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m#   and fall back to V0 for experimental or unsupported features.\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# * If VLLM_USE_V1=1, we enable V1 for supported + experimental\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m#   features and raise error for unsupported features.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# * If VLLM_USE_V1=0, we disable V1.\u001b[39;00m\n\u001b[1;32m    990\u001b[0m use_v1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/engine/arg_utils.py:875\u001b[0m, in \u001b[0;36mEngineArgs.create_model_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_WEIGHTS_S3_BUCKET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_format \u001b[38;5;241m=\u001b[39m LoadFormat\u001b[38;5;241m.\u001b[39mRUNAI_STREAMER\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModelConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhf_config_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_config_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_local_media_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallowed_local_media_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrope_theta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrope_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhf_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhf_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_model_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_model_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43menforce_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menforce_eager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_len_to_capture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_seq_len_to_capture\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_logprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_sliding_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_sliding_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_cascade_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_cascade_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_tokenizer_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskip_tokenizer_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_prompt_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_prompt_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserved_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserved_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit_mm_per_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimit_mm_per_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_async_output_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_async_output_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmm_processor_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm_processor_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_mm_preprocessor_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_mm_preprocessor_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_neuron_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverride_neuron_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_pooler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverride_pooler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor_pattern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits_processor_pattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_generation_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverride_generation_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_sleep_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_sleep_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_impl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_impl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:42\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, model, task, tokenizer, tokenizer_mode, trust_remote_code, dtype, seed, hf_config_path, allowed_local_media_path, revision, code_revision, rope_scaling, rope_theta, tokenizer_revision, max_model_len, spec_target_max_model_len, quantization, enforce_eager, max_seq_len_to_capture, max_logprobs, disable_sliding_window, disable_cascade_attn, skip_tokenizer_init, enable_prompt_embeds, served_model_name, limit_mm_per_prompt, use_async_output_proc, config_format, hf_token, hf_overrides, mm_processor_kwargs, disable_mm_preprocessor_cache, override_neuron_config, override_pooler_config, logits_processor_pattern, generation_config, override_generation_config, enable_sleep_mode, model_impl)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/config.py:583\u001b[0m, in \u001b[0;36mModelConfig.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_model_len \u001b[38;5;241m=\u001b[39m _get_and_verify_max_len(\n\u001b[1;32m    575\u001b[0m     hf_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_text_config,\n\u001b[1;32m    576\u001b[0m     max_model_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_model_len,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m     spec_target_max_model_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec_target_max_model_len,\n\u001b[1;32m    580\u001b[0m     encoder_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_config)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserved_model_name \u001b[38;5;241m=\u001b[39m get_served_model_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    582\u001b[0m                                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserved_model_name)\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultimodal_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_multimodal_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_tokenizer_init:\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_tokenizer_mode()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/config.py:651\u001b[0m, in \u001b[0;36mModelConfig._init_multimodal_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_multimodal_config\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiModalConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_multimodal_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marchitectures\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    652\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m MultiModalConfig(\n\u001b[1;32m    653\u001b[0m             limit_per_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit_mm_per_prompt,\n\u001b[1;32m    654\u001b[0m             mm_processor_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmm_processor_kwargs,\n\u001b[1;32m    655\u001b[0m             disable_mm_preprocessor_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    656\u001b[0m             disable_mm_preprocessor_cache)\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit_mm_per_prompt:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/model_executor/models/registry.py:512\u001b[0m, in \u001b[0;36m_ModelRegistry.is_multimodal_model\u001b[0;34m(self, architectures)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_multimodal_model\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     architectures: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m    511\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 512\u001b[0m     model_cls, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minspect_model_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43marchitectures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_cls\u001b[38;5;241m.\u001b[39msupports_multimodal\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/model_executor/models/registry.py:472\u001b[0m, in \u001b[0;36m_ModelRegistry.inspect_model_cls\u001b[0;34m(self, architectures)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (model_info, arch)\n\u001b[0;32m--> 472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_for_unsupported\u001b[49m\u001b[43m(\u001b[49m\u001b[43marchitectures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/model_executor/models/registry.py:422\u001b[0m, in \u001b[0;36m_ModelRegistry._raise_for_unsupported\u001b[0;34m(self, architectures)\u001b[0m\n\u001b[1;32m    419\u001b[0m all_supported_archs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_supported_archs()\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(arch \u001b[38;5;129;01min\u001b[39;00m all_supported_archs \u001b[38;5;28;01mfor\u001b[39;00m arch \u001b[38;5;129;01min\u001b[39;00m architectures):\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel architectures \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchitectures\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto be inspected. Please check the logs for more details.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel architectures \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchitectures\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are not supported for now. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported architectures: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_supported_archs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Model architectures ['LlavaForConditionalGeneration'] failed to be inspected. Please check the logs for more details."
     ]
    }
   ],
   "source": [
    "from vllm import LLM\n",
    "\n",
    "llm = LLM(model=\"llava-hf/llava-1.5-7b-hf\")\n",
    "\n",
    "# Refer to the HuggingFace repo for the correct format to use\n",
    "prompt = \"USER: <image>\\nWhat is the content of this image?\\nASSISTANT:\"\n",
    "\n",
    "# Load the image using PIL.Image\n",
    "image = PIL.Image.open(\"http://legacy-www.hpwren.ucsd.edu/FIgLib/HPWREN-FIgLib-Data/20250107_PalisadesFire_69bravo-e-mobo-c/1736274241_%2B00000.jpg\")\n",
    "\n",
    "# Single prompt inference\n",
    "outputs = llm.generate({\n",
    "    \"prompt\": prompt,\n",
    "    \"multi_modal_data\": {\"image\": image},\n",
    "})\n",
    "\n",
    "for o in outputs:\n",
    "    generated_text = o.outputs[0].text\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca3e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1538e554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd2352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c2d0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d4c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "# from IPython.display import display\n",
    "import numpy as np\n",
    "import base64\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import logging\n",
    "\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "\n",
    "def setup_logger():\n",
    "    \"\"\"Configure a comprehensive logger that overwrites files and includes timestamps\"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    # Clear any existing handlers\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "    \n",
    "    # Configure basic settings\n",
    "    logger.setLevel(logging.DEBUG)  # Set to lowest level\n",
    "    \n",
    "    # Create formatter with timestamp\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(levelname)-8s - %(filename)s:%(lineno)d - %(funcName)s() - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    \n",
    "    # File handler (overwrites existing file)\n",
    "    file_handler = logging.FileHandler('./logs/logs_val_llama3_test.log', mode='w', encoding='utf-8')\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    \n",
    "    # Console handler\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(logging.INFO)  # Only show INFO+ in console\n",
    "    console_handler.setFormatter(formatter)\n",
    "    \n",
    "    # Add handlers\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    # Initial log message\n",
    "    logger.info(f\"=== New session started at {datetime.now()} ===\")\n",
    "    \n",
    "    return logger\n",
    "\n",
    "# Initialize logger\n",
    "logger = setup_logger()\n",
    "\n",
    "\n",
    "# Ignore all DeprecationWarnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.sys.path.append(\"/expanse/lustre/projects/ddp464/mhnguyen/data\")\n",
    "\n",
    "\n",
    "# =========== select the model =========\n",
    "\n",
    "import openai\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"sk-PP2Y9C-TkPw_ZBRPnDQryQ\",\n",
    "    base_url=\"https://llm.nrp-nautilus.io\"\n",
    ")\n",
    "\n",
    "prompt = '''\n",
    "Analyze this image for wildfire smoke presence. Respond strictly in this format:\n",
    "\n",
    "Result: [Yes/No]\n",
    "Confidence: [0-10]\n",
    "Description: [2-3 sentence explanation of visual evidence]\n",
    "\n",
    "Rules:\n",
    "1. Focus only on visual smoke indicators (ignore text/logos)\n",
    "2. \"Yes\" requires clear visible smoke plumes\n",
    "3. Confidence 8+ needs unambiguous evidence\n",
    "4. Keep descriptions factual and concise\n",
    "'''\n",
    "\n",
    "# ========================================\n",
    "\n",
    "\n",
    "def parse_llm_fire_response(llm_output):\n",
    "    \"\"\"\n",
    "    Parses LLM output with robust fallback logic:\n",
    "    1. First tries structured formats (with/without bold)\n",
    "    2. Then looks for \"result:\" + yes/no\n",
    "    3. Finally checks for standalone yes/no keywords\n",
    "    \"\"\"\n",
    "    if not isinstance(llm_output, str):\n",
    "        return None\n",
    "\n",
    "    # Main pattern (handles bold/plain, case-insensitive)\n",
    "    main_pattern = (\n",
    "        r\"(?:\\*\\*)?Result(?:\\*\\*)?\\s*[:=]\\s*(?:\\*\\*)?(Yes|No)(?:\\*\\*)?\\s*\"\n",
    "        r\"(?:\\*\\*)?Confidence(?:\\*\\*)?\\s*[:=]\\s*(?:\\*\\*)?(\\d+)(?:\\*\\*)?\\s*\"\n",
    "        r\"(?:\\*\\*)?Description(?:\\*\\*)?\\s*[:=]\\s*(?:\\*\\*)?(.*?)(?:\\*\\*)?$\"\n",
    "    )\n",
    "    match = re.search(main_pattern, llm_output, re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        return {\n",
    "            'Result': match.group(1).strip().capitalize(),\n",
    "            'Confidence': int(match.group(2)),\n",
    "            'Description': match.group(3).strip()\n",
    "        }\n",
    "    \n",
    "    # Fallback 1: Look for \"result:\" + yes/no\n",
    "    result_match = re.search(\n",
    "        r\"(?:result|RESULT)\\s*[:=]\\s*(yes|no)\", \n",
    "        llm_output, \n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    if result_match:\n",
    "        return {\n",
    "            'Result': result_match.group(1).capitalize(),            \n",
    "        }\n",
    "    \n",
    "    # Fallback 2: Find standalone yes/no\n",
    "    standalone_yesno = re.search(\n",
    "        r\"\\b(yes|no)\\b\", \n",
    "        llm_output, \n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    if standalone_yesno:\n",
    "        return {\n",
    "            'Result': standalone_yesno.group(1).capitalize(),\n",
    "        }\n",
    "    \n",
    "    return None    \n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"Convert local image to base64 data URI\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return f\"data:image/jpeg;base64,{base64.b64encode(image_file.read()).decode('utf-8')}\"\n",
    "\n",
    "with open('val_fires_final.txt', 'r') as file:\n",
    "    val_fire_names = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "fire_scores = {}\n",
    "fires_covered = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for fire in tqdm(os.listdir(\"/expanse/lustre/projects/ddp464/mhnguyen/data\"), desc='processing images...'):\n",
    "\n",
    "    if fire in val_fire_names:\n",
    "        \n",
    "        logger.info(f\"=============== {fire} ===============\")\n",
    "        image_dir = f\"/expanse/lustre/projects/ddp464/mhnguyen/data/{fire}\"\n",
    "\n",
    "        # Get all files and sort them alphabetically (start with negative sample and then positives...)\n",
    "        image_files = sorted([f for f in os.listdir(image_dir)\n",
    "                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        time_to_detect = 0\n",
    "        predictions = list()\n",
    "\n",
    "        for image_name in image_files:\n",
    "            image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "            # Determine target_label based on image name\n",
    "            if '-' in image_name:\n",
    "                target_label = 0\n",
    "            elif '+' in image_name:\n",
    "                target_label = 1\n",
    "            else:\n",
    "                target_label = -1  # default case if neither - nor + is found\n",
    "\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                            model=\"llama3\",\n",
    "                            messages=[\n",
    "                                {\n",
    "                                    \"role\": \"user\",\n",
    "                                    \"content\": [\n",
    "                                        {\"type\": \"text\", \"text\": f'''{prompt}'''},\n",
    "                                        {\"type\": \"image_url\",\n",
    "                                        \"image_url\":\n",
    "                                        {\n",
    "                                            \"url\": f\"{encode_image(image_path)}\",\n",
    "                                            \"format\": \"image/jpeg\"}\n",
    "                                        },\n",
    "                                    ],\n",
    "                                }\n",
    "                            ],\n",
    "                        )\n",
    "\n",
    "                llm_output = response.choices[0].message.content\n",
    "                logger.info(llm_output)\n",
    "                parsed_result = parse_llm_fire_response(llm_output)\n",
    "                logger.info(parsed_result)\n",
    "                if parsed_result:\n",
    "                    # logger.info(f\"Result: {parsed_result['Result']}\")\n",
    "                    # logger.info(f\"Confidence: {parsed_result['Confidence']}\")\n",
    "                    # logger.info(f\"Description: {parsed_result['Description']}\")\n",
    "                    if parsed_result['Result'].lower() == \"yes\":\n",
    "                        result = \"Yes\"\n",
    "                    else:\n",
    "                        result = \"No\"\n",
    "                else:\n",
    "                    logger.info(\"Failed to parse LLM output.  Output was not in the expected format.\")\n",
    "                    result = \"No\"\n",
    "\n",
    "                if result == 'Yes' and target_label == 1:\n",
    "                    tp += 1\n",
    "                    if tp == 1:\n",
    "                        idx = image_name.find(\"+\")\n",
    "                        time_to_detect = int(image_name[idx:-4])\n",
    "\n",
    "                elif result == 'Yes' and target_label == 0:\n",
    "                    fp += 1\n",
    "\n",
    "                elif result == 'No' and target_label == 1:\n",
    "                    fn += 1\n",
    "\n",
    "                if result == \"Yes\":\n",
    "                    predictions.append(1)\n",
    "                else:\n",
    "                    predictions.append(0)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.info(f\"Error processing {image_name}: {str(e)}\")\n",
    "\n",
    "\n",
    "        fire_scores[fire] = {\n",
    "                        \"precision\": round(tp / (tp + fp), 2) if (tp + fp) != 0 else 0.0,\n",
    "                        \"recall\": round(tp / (tp + fn), 2) if (tp + fn) != 0 else 0.0,\n",
    "                        \"f1_score\": round(tp / (tp + 0.5 * (fp + fn)), 2) if (tp + 0.5 * (fp + fn)) != 0 else 0.0,\n",
    "                        \"time_to_detect\": time_to_detect,\n",
    "                        \"true_positives\": tp,\n",
    "                        \"false_positives\": fp,\n",
    "                        \"false_negatives\": fn,\n",
    "                        \"predictions\": predictions\n",
    "                            }\n",
    "        \n",
    "        fires_covered += 1\n",
    "        logger.info(f\"---------- Fires covered : {fires_covered} ------------------\")\n",
    "        if fires_covered % 5 == 0:\n",
    "            logger.info(f\"======== Count of fires: {fires_covered} =======\")\n",
    "            avg_precision = np.mean([v['precision'] for k,v in fire_scores.items()])\n",
    "            avg_recall = np.mean([v['recall'] for k,v in fire_scores.items()])\n",
    "            avg_f1_score = np.mean([v['f1_score'] for k,v in fire_scores.items()])\n",
    "            avg_time_to_detect = np.mean([v['time_to_detect'] for k,v in fire_scores.items()])\n",
    "\n",
    "            logger.info(f\"Average Precision: {avg_precision}\")\n",
    "            logger.info(f\"Average Recall: {avg_recall}\")\n",
    "            logger.info(f\"Average F1 score: {avg_f1_score}\")\n",
    "            logger.info(f\"Average time to detect: {avg_time_to_detect}\")\n",
    "            logger.info(f\"Time taken: {time.time() - start_time} secs\")\n",
    "            # break\n",
    "        \n",
    "avg_precision = np.mean([v['precision'] for k,v in fire_scores.items()])\n",
    "avg_recall = np.mean([v['recall'] for k,v in fire_scores.items()])\n",
    "avg_f1_score = np.mean([v['f1_score'] for k,v in fire_scores.items()])\n",
    "avg_time_to_detect = np.mean([v['time_to_detect'] for k,v in fire_scores.items()])\n",
    "\n",
    "logger.info(f\"Overall Average Precision: {avg_precision}\")\n",
    "logger.info(f\"Overall Average Recall: {avg_recall}\")\n",
    "logger.info(f\"Overall Average F1 score: {avg_f1_score}\")\n",
    "logger.info(f\"Overall Average time to detect: {avg_time_to_detect}\")\n",
    "\n",
    "# Save to a pickle file\n",
    "with open(\"fire_scores_llama3.pickle\", \"wb\") as file:  # 'wb' = write in binary mode\n",
    "    pickle.dump(fire_scores, file)\n",
    "\n",
    "logger.info(\"============= File saved ================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
